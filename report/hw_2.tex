%!TEX program = xelatex

\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
\usepackage[final]{neurips_2021}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2021}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage[UTF8]{ctex}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{multirow}
\newtheorem{definition}{定义}
\newtheorem{theorem}{定理}
\usepackage{subcaption}
\usepackage[export]{adjustbox}

\setCJKmainfont{SimSun}[AutoFakeBold=2.5,ItalicFont=KaiTi]%
\setCJKsansfont{SimHei}[AutoFakeBold=2.5]%
\setCJKmonofont{FangSong}%


\title{《最优化方法》上机作业2：大规模优化问题的数值实验}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  张旻昊 Minhao Zhang 2101213233 \\
  前沿交叉学科研究院 Academy for Advanced Interdisciplinary Studies\\
  北京大学 Peking University\\
  颐和园路5号，海淀，北京 Yiheyuan Rd. $5^{th}$, Haidian, Beijing\\
  \texttt{minhaozhang@pku.edu.cn} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}
%\begin{CJK*}{UTF8}{gbsn}

\maketitle

\begin{abstract}
  本实验实现了两种共轭梯度方法、基于Beale-Powell重新开始的三项方法及L-BFGS方法的程序，并利用Ackley、Rastrigin等多个函数在大规模设定下测试各方法的收敛表现。
  
\end{abstract}

\section{实验设定}
\subsection{目标函数选取}
本实验使用如下三种目标函数进行测试。在实验中均使用n>100以测试大规模场景下的性能，所有算法均旨在寻找局部极小值。

\subsubsection{Ackley函数}

Ackley函数形式为：
\[ \texttt{Ackley}(x) = -20 exp[-\frac{1}{5} \sqrt{\frac{1}{n}\sum\limits_{i=1}^n x_i^2}] - exp[\frac{1}{n} \sum\limits_{i=1}^n cos(2\pi x_i)] + 20+e \]

Ackley函数具有全局最小值$x^* = (0,0,...,0), f(x^*)=0$，此外它还有众多极小值。

\subsubsection{Griewank函数}
Griewank函数形式为：
\[ \texttt{Griewank}(x) = \frac{1}{4000}\sum\limits_{i=1}^n x_i^2 - \prod\limits_{i=1}^n cos(\frac{x_i}{\sqrt{i}}) + 1 \]
它在$x^* = (0,0,...,0)$处取全局极小值$f(x^*)=0$，同时也具有众多局部极小值。

\subsubsection{Rastrigin函数}
Rastrigin函数形式为：
\[ \texttt{Rastrigin}(x) = 10n + \sum\limits_{i=0}^n [x_i^2 - 10cos(2\pi x_i)] \]
其全局极小值$f(x^*)=0$同样在$x^* = (0,0,...,0)$取得，它也具有众多局部极小值。

\subsection{拟Newton方法}
本实验实现有限内存BFGS方法（L-BFGS），不同于BFGS方法计算$H_k$，它直接计算$d_k$，进而让存储开销从$O(n^2)$降低到$O(n)$。具体地，L-BFGS方法将$H_k$更新公式的最近m步进行展开，这样只需存储最近m步的$s_k = x_k - x_{k-1}$和$yk = g_k - g_{k-1}$，并根据图\ref{fig:lbfgs}即可求得$d_k = -r_{BOUND}$。

\begin{figure}[h]
  \centering
  \includegraphics[width=.8\linewidth]{pics/lbfgs_two_loop.jpg}
  \caption{L-BFGS方法通过two-loop算法更新$d_k$。}
  \label{fig:lbfgs}
\end{figure}

\subsection{共轭梯度法}
本实验实现基于FR与PRP两种$\beta_k$更新公式的共轭梯度方法，具体实现与教材中完全相同，这里不再赘述。

\subsection{三项方法}
共轭梯度法实际上是一种二项的梯度型方法，为提升求解精度，Beale-Powell提出了一种包含三项的方向更新公式，本实验实现了这一方法。此算法基于如下更新公式：
\[ \beta_k = g_k^T [g_k - g_{k-1}] / d_{k-1}^T [g_k - g_{k-1}] \]
\[ \gamma_k = g_k^T [g_{t+1} - g_t] / d_t^T [g_{t+1} - g_t] \]
\[ d_k = -g_k + \beta_k d_{k-1} + \gamma_k d_{t} \]

此外，当更新方向不够好时，使用restart的方法更新t=k-1，并设置$\gamma_k=0$（即使用二项公式更新）。存在如下三种restart条件：1)当$g_k^T g_{k-1} \geq 0.2 ||g_k||^2$时，梯度正交性不足，设置重新开始；2)当$k-t\geq n$时，所有理想共轭方向已经用过了，重新开始；3)求出上述$d_k$后，若$-1.2||g_k||^2\leq d_k^T g_k\leq -0.8||g_k||^2$不满足，则重新开始，并重新舍弃第三项计算$d_k$。


\section{实验结果}
本节分别在三个测试函数上比较各方法的实验效果。在实验中，均使用20次迭代的Fibonacci搜索进行精确线搜索；作为基准方法，我们同时与基于Cholesky分解的修正Newton方法、BFGS拟Newton方法进行比较。

\subsection{Ackley函数上的实验}
表\ref{tab:ackley}总结了上述方法在Ackley函数上的结果。对此可做如下分析：
\begin{itemize}
  \item 对比拟Newton方法和共轭梯度类方法，可以发现前者总体优于后者。所有拟Newton方法在所有规模下均实现收敛，而三类共轭梯度类方法常常无法收敛，达到最大循环次数退出。虽然后者的一阶性具有更高性能，但由于收敛性不佳，往往耗费更多迭代次数，这反而影响了它的效率。
  \item 共轭梯度类方法在正定二次函数中具有很好的理论表现，但在此处实际表现不佳，说明了实际问题的复杂性，我们通常不能期望在一小类问题上具有良好理论基础的方法总是具有很好的泛化能力，实际上，共轭梯度法并不比拟Newton法更通用。
  \item 在拟Newton方法中，L-BFGS相比BFGS具有更优的数值表现，这体现在它具有更快的运行速度。二者虽然总迭代次数相仿（L-BFGS有时反而更多），但舍弃Hessian矩阵的存储使L-BFGS效率更高，总体运行时间显著低于BFGS。
  \item 在共轭梯度类方法中，首先PRP方法显著优于FR方法，这体现在FR方法最终退出时$g^*$往往处在1e-1量级，这通常是不可接受的；作为对比，PRP虽经常无法达到$\epsilon$精度，但也有1e-6的精度，可以接受。在正定二次函数中，PRP与FR等价；但在我们的实际应用中，二者性能差别很大，这说明最优化方法往往需要更多的实践分析。
  \item 其次，Beale-Powell三项方法虽属于对PRP的改进，但在Ackley函数上体现的数值表现差别并不明显，它在多数情况下能取得比PRP更优的精度，但此时需要消耗更多的CPU时间，实际中需权衡时间效率与精度选择两算法。
\end{itemize}

\begin{table*}[h]
  \centering
  \begin{tabular}{c l c c c c c c c}
    \toprule
    \bfseries n & \bfseries Methods & \boldmath{$f(x^*)$} & \boldmath $||g(x^*)||$ & \bfseries Time(s) & \bfseries niter & \bfseries feval & \bfseries geval & \bfseries Geval \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{100} &
    BFGS & 3.8710 & $<\epsilon$ & 0.0928 & 38 & 77 & 39 & 0 \\
    & L-BFGS & 3.9730 & $<\epsilon$ & 0.0509 & 22 & 46 & 23 & 0 \\
    & FR & 5.0915 & 6e-1 & 0.3900 & 300 & 1376 & 300 & 0 \\
    & PRP & 5.7260 & 3e-7 & 0.2344 & 300 & 600 & 300 & 0 \\
    & BP & 5.7260 & 3e-7 & 0.2663 & 300 & 600 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{200} &
    BFGS & 6.0790 & $<\epsilon$ & 0.0844 & 27 & 57 & 28 & 0 \\
    & L-BFGS & 6.0790 & $<\epsilon$ & 0.0419 & 26 & 55 & 27 & 0 \\
    & FR & 5.4226 & 5e-1 & 0.2970 & 300 & 1162 & 300 & 0 \\
    & PRP & 6.1057 & 6e-7 & 0.1865 & 300 & 600 & 300 & 0 \\
    & BP & 6.1057 & 3e-7 & 0.2327 & 300 & 600 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{300} &
    BFGS & 6.5189 & $<\epsilon$ & 0.2682 & 34 & 69 & 35 & 0 \\
    & L-BFGS & 6.5189 & $<\epsilon$ & 0.0549 & 33 & 67 & 34 & 0 \\
    & FR & 6.3083 & 3e-1 & 0.2473 & 300 & 950 & 300 & 0 \\
    & PRP & 6.5730 & 2e-6 & 0.7405 & 300 & 1326 & 300 & 0 \\
    & BP & 6.5730 & 3e-6 & 0.4181 & 300 & 1324 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{400} &
    BFGS & 5.8927 & $<\epsilon$ & 0.5834 & 45 & 94 & 46 & 0 \\
    & L-BFGS & 5.8827 & $<\epsilon$ & 0.0959 & 44 & 92 & 45 & 0 \\
    & FR & 6.0529 & 3e-1 & 0.3042 & 300 & 971 & 300 & 0 \\
    & PRP & 6.3071 & 7e-7 & 0.2174 & 300 & 600 & 300 & 0 \\
    & BP & 5.9703 & 8e-7 & 0.2352 & 300 & 600 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{500} &
    BFGS & 6.3447 & $<\epsilon$ & 0.7310 & 33 & 67 & 34 & 0 \\
    & L-BFGS & 6.3447 & $<\epsilon$ & 0.0798 & 44 & 89 & 45 & 0 \\
    & FR & 6.4770 & 3e-1 & 0.2882 & 300 & 1080 & 300 & 0 \\
    & PRP & 6.3518 & 2e-5 & 0.5008 & 300 & 2325 & 300 & 0 \\
    & BP & 6.3146 & 9e-6 & 0.2424 & 300 & 601 & 300 & 0 \\
    \bottomrule
  \end{tabular}
  \caption{各类方法在Ackley函数上的比较。所有算法均使用Fibonacci法进行精确线搜索。表中BP指基于Beale-Powell restart的三项方法，其余方法见前述介绍；Time指CPU时间，niter为迭代轮数，feval、geval和Geval分别指愿函数、一阶导数及hessian矩阵的计算次数。$\epsilon=1e-8$。}
  \label{tab:ackley}
\end{table*}

\begin{table*}[t]
  \centering
  \begin{tabular}{c l c c c c c c c}
    \toprule
    \bfseries n & \bfseries Methods & \boldmath{$f(x^*)$} & \boldmath $||g(x^*)||$ & \bfseries Time(s) & \bfseries niter & \bfseries feval & \bfseries geval & \bfseries Geval \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{100} &
    BFGS & 0.0000 & $<\epsilon$ & 0.1379 & 32 & 98 & 33 & 0 \\
    & L-BFGS & 0.0000 & $<\epsilon$ & 0.1554 & 32 & 98 & 33 & 0 \\
    & FR & 0.0632 & 2e-1 & 0.7446 & 300 & 2109 & 300 & 0 \\
    & PRP & 8.9937 & 9e-2 & 0.6406 & 300 & 300 & 300 & 0 \\
    & BP & 10.2864 & 1e-1 & 0.7512 & 300 & 300 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{200} &
    BFGS & 0.0000 & $<\epsilon$ & 0.1809 & 43 & 131 & 44 & 0 \\
    & L-BFGS & 0.0000 & $<\epsilon$ & 0.1047 & 44 & 134 & 45 & 0 \\
    & FR & 0.4132 & 6e-1 & 1.4345 & 300 & 2555 & 300 & 0 \\
    & PRP & 16.0523 & 1e-1 & 0.2713 & 300 & 900 & 300 & 0 \\
    & BP & 18.4863 & 1e-1 & 0.5484 & 300 & 900 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{300} &
    BFGS & 0.0000 & $<\epsilon$ & 1.0055 & 47 & 143 & 48 & 0 \\
    & L-BFGS & 0.0000 & $<\epsilon$ & 0.2038 & 51 & 155 & 52 & 0 \\
    & FR & 0.4090 & 7e-1 & 0.9568 & 300 & 2515 & 300 & 0 \\
    & PRP & 21.4195 & 1e-1 & 0.4876 & 300 & 900 & 300 & 0 \\
    & BP & 24.7214 & 1e-1 & 0.7672 & 300 & 900 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{400} &
    BFGS & 0.0000 & $<\epsilon$ & 1.7973 & 53 & 161 & 54 & 0 \\
    & L-BFGS & 0.0000 & $<\epsilon$ & 0.3073 & 59 & 179 & 60 & 0 \\
    & FR & 0.4548 & 7e-1 & 1.2051 & 300 & 2437 & 300 & 0 \\
    & PRP & 31.4980 & 2e-1 & 0.5822 & 300 & 900 & 300 & 0 \\
    & BP & 36.4296 & 2e-1 & 0.7491 & 300 & 900 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{500} &
    BFGS & 0.0000 & $<\epsilon$ & 3.0199 & 59 & 179 & 60 & 0 \\
    & L-BFGS & 0.0000 & $<\epsilon$ & 0.3536 & 62 & 188 & 63 & 0 \\
    & FR & 0.6047 & 7e-1 & 1.1978 & 300 & 2030 & 300 & 0 \\
    & PRP & 36.9223 & 2e-1 & 0.9250 & 300 & 900 & 300 & 0 \\
    & BP & 42.7311 & 2e-1 & 0.9682 & 300 & 900 & 300 & 0 \\
    \bottomrule
  \end{tabular}
  \caption{各类方法在Griewank函数上的比较。所有算法均使用Fibonacci法进行精确线搜索。表中BP指基于Beale-Powell restart的三项方法，其余方法见前述介绍；Time指CPU时间，niter为迭代轮数，feval、geval和Geval分别指愿函数、一阶导数及hessian矩阵的计算次数。$\epsilon=1e-8$。}
  \label{tab:griewank}
\end{table*}

\subsection{Griewank函数上的实验}
上述方法在Griewank上的实验结果如表\ref{tab:griewank}所示，我们做出如下分析：
\begin{itemize}
  \item Griewank上的结果基本与Ackley上的情形类似，拟Newton方法普遍优于共轭梯度类方法，前者可以实现$\epsilon$一下的收敛，后者不可。此外，在拟Newton方法内部，随着问题规模增大，L-BFGS相比BFGS的性能优势逐渐增大，在n=500的规模上L-BFGS相比BFGS可加速近10倍。
  \item 在共轭梯度类方法内部，PRP和BP相比FR收敛精度更好，这体现在更小的$||g^*||$；然而，FR方法最终可收敛到相对更小函数值$f^*$，即找到更好地局部极值点。
  \item 对比PRP与BP方法，二者收敛精度类似，但PRP始终比BP略好一点，这说明BP虽作为PRP的改进，但未必在所有情形中均可优于PRP方法。
\end{itemize}

\subsection{Rastrigin函数上的实验}
在Rastrigin函数上的结果如表\ref{tab:rastrigin}所示，分析如下：
\begin{itemize}
  \item 拟Newton方法与共轭梯度类方法的对比与之前相似，前者精度仍显著高于后者；但在此函数上拟Newton方法往往需要更多的迭代次数才能收敛，这使其CPU时间更长，效率总体不佳；然而考虑到共轭梯度法收敛精度不佳，我们并不能断定拟Newton法在Rastrigin上具有劣势。
  \item 在拟Newton方法中，BFGS的收敛精度高于L-BFGS，这与前文的结论不同，说明L-BFGS也并非总是优于BFGS。然而，L-BFGS往往能收敛至相比BFGS更小的函数值，这可能是由于在迭代初期它的更新步长以估算为主，偏向于梯度方向进而更快的向原点变化，而非很快地接近局部极小值，进而最终收敛于更靠近原点、函数值更小的局部极小值。
  \item 在共轭梯度类方法中，BP方法收敛精度$||g^*||$显著高于其他两种方法，体现了其改进的优势，但总体而言共轭梯度类方法精度仍不理想。
\end{itemize}

\begin{table*}[t]
  \centering
  \begin{tabular}{c l c c c c c c c}
    \toprule
    \bfseries n & \bfseries Methods & \boldmath{$f(x^*)$} & \boldmath $||g(x^*)||$ & \bfseries Time(s) & \bfseries niter & \bfseries feval & \bfseries geval & \bfseries Geval \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{100} &
    BFGS & 661.6343 & $<\epsilon$ & 0.5457 & 201 & 1349 & 202 & 0 \\
    & L-BFGS & 414.8923 & 6e-6 & 12.4202 & 2000 & 20734 & 2000 & 0 \\
    & FR & 215.4769 & 1e2 & 0.7437 & 300 & 4059 & 300 & 0 \\
    & PRP & 435.7878 & 1e-1 & 0.7899 & 300 & 4974 & 300 & 0 \\
    & BP & 365.1468 & 1e-2 & 0.5958 & 300 & 3179 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{200} &
    BFGS & 1198.9077 & $<\epsilon$ & 1.1925 & 324 & 2329 & 325 & 0 \\
    & L-BFGS & 889.4847 & 1e-5 & 9.0090 & 2000 & 21931 & 2000 & 0 \\
    & FR & 563.6295 & 2e2 & 0.8198 & 300 & 4278 & 300 & 0 \\
    & PRP & 781.0367 & 2e-1 & 0.7929 & 300 & 4719 & 300 & 0 \\
    & BP & 706.4160 & 4e-1 & 0.6663 & 300 & 3145 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{300} &
    BFGS & 1820.6969 & $<\epsilon$ & 8.7206 & 429 & 2997 & 430 & 0 \\
    & L-BFGS & 1300.3976 & 2e-5 & 12.7279 & 2000 & 22577 & 2000 & 0 \\
    & FR & 1133.5034 & 4e2 & 2.6154 & 300 & 4213 & 300 & 0 \\
    & PRP & 861.6311 & 5e-1 & 2.3425 & 300 & 5940 & 300 & 0 \\
    & BP & 1117.3306 & 4e-1 & 1.6367 & 300 & 3146 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{400} &
    BFGS & 2010.7760 & $<\epsilon$ & 9.7254 & 495 & 3454 & 496 & 0 \\
    & L-BFGS & 2097.3385 & 2e-5 & 11.3404 & 2000 & 21159 & 2000 & 0 \\
    & FR & 1876.4243 & 6e2 & 1.2880 & 300 & 4163 & 300 & 0 \\
    & PRP & 2120.4749 & 5e1 & 1.0073 & 300 & 3395 & 300 & 0 \\
    & BP & 1755.0962 & 5e-1 & 1.1807 & 300 & 3160 & 300 & 0 \\
    \cmidrule(lr){1-9}
    \multirow{5}{*}{500} &
    BFGS & 2447.5556 & 1e-6 & 15.2244 & 499 & 3738 & 500 & 0 \\
    & L-BFGS & 1867.5232 & 2e-5 & 9.7453 & 2000 & 20747 & 2000 & 0 \\
    & FR & 2295.3027 & 6e2 & 0.6888 & 300 & 4156 & 300 & 0 \\
    & PRP & 3119.1587 & 5e-1 & 0.7628 & 300 & 4636 & 300 & 0 \\
    & BP & 1945.1230 & 5e-1 & 0.8665 & 300 & 3175 & 300 & 0 \\
    \bottomrule
  \end{tabular}
  \caption{各类方法在Rastrigin函数上的比较。所有算法均使用Fibonacci法进行精确线搜索。表中BP指基于Beale-Powell restart的三项方法，其余方法见前述介绍；Time指CPU时间，niter为迭代轮数，feval、geval和Geval分别指愿函数、一阶导数及hessian矩阵的计算次数。$\epsilon=1e-8$。}
  \label{tab:rastrigin}
\end{table*}


\section{总结}
本文比较了几种拟Newton方法与共轭梯度方法在多个测试函数上的数值表现，分析了二者的优劣；总体而言，拟牛顿法精度好于共轭梯度法，这说明后者对非正定二次函数的泛化表现并不令人满意；L-BFGS相比BFGS实现了显著的性能提升；Beale-Powell三项方法在共轭梯度法中表现相对更优。


%end{CJK*}
\end{document}
